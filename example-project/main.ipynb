{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPU Check Demo\n",
        "\n",
        "A minimal notebook to verify GPU access on Brev.\n",
        "Runs in under 30 seconds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if PyTorch is available\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    TORCH_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"PyTorch not installed - install with: pip install torch\")\n",
        "    TORCH_AVAILABLE = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check CUDA availability\n",
        "if TORCH_AVAILABLE:\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    print(f\"CUDA available: {cuda_available}\")\n",
        "    \n",
        "    if cuda_available:\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        print(f\"GPU count: {gpu_count}\")\n",
        "        \n",
        "        for i in range(gpu_count):\n",
        "            gpu_name = torch.cuda.get_device_name(i)\n",
        "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
        "            print(f\"GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
        "    else:\n",
        "        print(\"No GPU detected - running on CPU\")\n",
        "else:\n",
        "    print(\"Skipping GPU check (PyTorch not installed)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick GPU test (if available)\n",
        "if TORCH_AVAILABLE and torch.cuda.is_available():\n",
        "    print(\"Running quick GPU tensor test...\")\n",
        "    x = torch.randn(1000, 1000, device='cuda')\n",
        "    y = torch.randn(1000, 1000, device='cuda')\n",
        "    z = torch.matmul(x, y)\n",
        "    print(f\"Matrix multiply result shape: {z.shape}\")\n",
        "    print(\"âœ“ GPU test passed!\")\n",
        "else:\n",
        "    print(\"GPU test skipped\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Demo complete!\")\n",
        "print(\"=\"*50)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
